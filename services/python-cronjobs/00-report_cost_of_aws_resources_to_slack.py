# =============================================================================
# AWS COST REPORT CRON JOB (ARCHIVED)
# =============================================================================
# This cron job has been archived and is currently disabled.
# 
# ARCHIVE REASON: Slack notifications disabled, cron execution paused
# ARCHIVE DATE: Current session
# 
# TO RESTORE:
# 1. Uncomment the main() function execution code
# 2. Remove the early return guard in main()
# 3. Optionally restore Slack functionality from archived sections
# 4. Update your cron scheduler to re-enable execution
#
# =============================================================================

import boto3
import os
# ARCHIVED: Slack functionality temporarily disabled
# from slackbot import slack
import pandas as pd
from tabulate import tabulate
import pytz
from datetime import datetime, timedelta
import time
import math

# AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
athena_client = boto3.client('athena')

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# ARCHIVED: Slack channel ID temporarily disabled
# SLACK_CHANNEL_ID = os.getenv('SLACK_CHANNEL_ID', 'C07A8FBE2Q6')
DATABASE_NAME = os.getenv('DATABASE_NAME', 'vpc_flow_logs_db')
ATHENA_OUTPUT_LOCATION = os.getenv('ATHENA_OUTPUT_LOCATION', 's3://example-org-devops/report/')

def execute_athena_query(query, database):
    try:
        print("\nExecuting query:")
        print(query)  # ì‹¤ì œ ì‹¤í–‰ë˜ëŠ” ì¿¼ë¦¬ ì¶œë ¥
        
        response = athena_client.start_query_execution(
            QueryString=query,
            QueryExecutionContext={'Database': database},
            ResultConfiguration={'OutputLocation': ATHENA_OUTPUT_LOCATION}
        )
        
        query_execution_id = response['QueryExecutionId']
        print(f"Query execution ID: {query_execution_id}")
        
        # ì¿¼ë¦¬ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 300ì´ˆë¡œ ì¦ê°€)
        for _ in range(300):  # 120ì´ˆì—ì„œ 300ì´ˆë¡œ ì¦ê°€
            response = athena_client.get_query_execution(QueryExecutionId=query_execution_id)
            state = response['QueryExecution']['Status']['State']
            
            if state == 'FAILED':
                error_details = response['QueryExecution']['Status'].get('StateChangeReason', 'No error details available')
                print(f"Query failed. Error details: {error_details}")
                return pd.DataFrame()
                
            if state == 'SUCCEEDED':
                print("Query completed successfully")
                response = athena_client.get_query_results(QueryExecutionId=query_execution_id)
                # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                columns = [col['Label'] for col in response['ResultSet']['ResultSetMetadata']['ColumnInfo']]
                data = []
                for row in response['ResultSet']['Rows'][1:]:  # Skip header
                    data.append([field.get('VarCharValue', '') for field in row['Data']])
                df = pd.DataFrame(data, columns=columns)
                print(f"\nQuery results shape: {df.shape}")  # ê²°ê³¼ í¬ê¸° ì¶œë ¥
                return df
            
            if state == 'CANCELLED':
                print("Query was cancelled")
                return pd.DataFrame()
                
            print(f"Query state: {state}, waiting... (Attempt {_+1}/300)")
            time.sleep(1)
        
        print("Query timed out after 300 seconds")
        return pd.DataFrame()
        
    except Exception as e:
        print(f"Error executing Athena query: {str(e)}")
        print(f"Full error details: {e.__dict__}")
        return pd.DataFrame()

def format_bytes(bytes_value):
    """ë°”ì´íŠ¸ ê°’ì„ ì ì ˆí•œ ë‹¨ìœ„(MB, GB, TB)ë¡œ ë³€í™˜"""
    try:
        bytes_value = float(bytes_value)
        if bytes_value == 0:
            return "0 B"
        units = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']
        k = 1024.0
        i = int(math.floor(math.log(bytes_value, k)))
        if i >= len(units):
            i = len(units) - 1
        return f"{bytes_value / (k**i):.2f} {units[i]}"
    except (ValueError, TypeError):
        return "0 B"

def get_data_transfer_metrics():
    kst = pytz.timezone('Asia/Seoul')
    today = datetime.now(kst)
    yesterday = today - timedelta(days=1)
    
    query_params = {
        'year': today.year,
        'month': today.month,
        'day': today.day,
        'prev_year': yesterday.year,
        'prev_month': yesterday.month,
        'prev_day': yesterday.day
    }

    print(f"Querying for dates: Today={today.date()}, Yesterday={yesterday.date()}")

    # ì „ì¼ ëŒ€ë¹„ ì´ íŠ¸ë˜í”½ ë³€í™”ëŸ‰ ì¿¼ë¦¬
    traffic_comparison_query = """
    WITH today AS (
        SELECT 
            CAST(SUM(bytes) AS DOUBLE) / POWER(1024, 3) as total_gb,
            COUNT(DISTINCT srcaddr) as unique_sources,
            COUNT(DISTINCT dstaddr) as unique_destinations
        FROM vpc_flow_logs
        WHERE year = {year} AND month = {month} AND day = {prev_day}
    ),
    yesterday AS (
        SELECT 
            CAST(SUM(bytes) AS DOUBLE) / POWER(1024, 3) as total_gb,
            COUNT(DISTINCT srcaddr) as unique_sources,
            COUNT(DISTINCT dstaddr) as unique_destinations
        FROM vpc_flow_logs
        WHERE year = {prev_year} AND month = {prev_month} AND day = {prev_day}
    )
    SELECT 
        today.total_gb as today_gb,
        yesterday.total_gb as yesterday_gb,
        ((today.total_gb - yesterday.total_gb) / NULLIF(yesterday.total_gb, 0) * 100) as change_percentage,
        today.unique_sources as today_unique_sources,
        today.unique_destinations as today_unique_destinations
    FROM today, yesterday
    """.format(**query_params)
    
    traffic_comparison_df = execute_athena_query(traffic_comparison_query, DATABASE_NAME)
    print("\nQuery results:")
    print(traffic_comparison_df)
    
    if traffic_comparison_df.empty:
        print("Warning: No results returned from traffic comparison query")
    else:
        print("\nTraffic comparison details:")
        print(f"Today's GB: {traffic_comparison_df['today_gb'].iloc[0]}")
        print(f"Yesterday's GB: {traffic_comparison_df['yesterday_gb'].iloc[0]}")
        print(f"Change percentage: {traffic_comparison_df['change_percentage'].iloc[0]}%")

    # ì†ŒìŠ¤ IPë³„ ì†¡ì‹  íŠ¸ë˜í”½
    source_ips_query = """
    SELECT 
        srcaddr AS ip,
        CAST(SUM(bytes) AS DOUBLE) as total_bytes_sent,
        COUNT(*) as request_count
    FROM vpc_flow_logs
    WHERE year = {year} AND month = {month} AND day = {prev_day}
    GROUP BY srcaddr
    ORDER BY total_bytes_sent DESC
    LIMIT 10
    """.format(**query_params)

    # ëŒ€ìƒ IPë³„ ìˆ˜ì‹  íŠ¸ë˜í”½
    dest_ips_query = """
    SELECT 
        dstaddr AS ip,
        CAST(SUM(bytes) AS DOUBLE) as total_bytes_received,
        COUNT(*) as request_count
    FROM vpc_flow_logs
    WHERE year = {year} AND month = {month} AND day = {prev_day}
    GROUP BY dstaddr
    ORDER BY total_bytes_received DESC
    LIMIT 10
    """.format(**query_params)

    # ì¸ìŠ¤í„´ìŠ¤ë³„ íŠ¸ë˜í”½
    instance_traffic_query = """
    SELECT 
        instance_id,
        srcaddr,
        CAST(SUM(bytes) AS DOUBLE) as total_bytes,
        SUM(packets) as total_packets
    FROM vpc_flow_logs
    WHERE year = {year} 
        AND month = {month} 
        AND day = {prev_day}
        AND instance_id <> '-'
    GROUP BY instance_id, srcaddr
    ORDER BY total_bytes DESC
    LIMIT 20
    """.format(**query_params)

    # ì¸ìŠ¤í„´ìŠ¤ë³„ ì¸ë°”ìš´ë“œ/ì•„ì›ƒë°”ìš´ë“œ íŠ¸ë˜í”½ ì¿¼ë¦¬ ì¶”ê°€
    instance_direction_query = """
    SELECT 
        instance_id,
        flow_direction,
        CAST(SUM(bytes) AS DOUBLE) as total_bytes,
        COUNT(*) as connection_count
    FROM vpc_flow_logs
    WHERE year = {year} 
        AND month = {month} 
        AND day = {prev_day}
        AND instance_id <> '-'
    GROUP BY instance_id, flow_direction
    ORDER BY instance_id, flow_direction
    """.format(**query_params)

    # IP ìŒë³„ íŠ¸ë˜í”½ ì¿¼ë¦¬ ì¶”ê°€
    ip_pairs_query = """
    SELECT
        action,
        interface_id,
        instance_id,
        flow_direction,
        log_status,
        srcaddr,
        srcport,  
        dstaddr,
        dstport,
        protocol,
        CAST(SUM(bytes) AS DOUBLE) AS total_bytes
    FROM vpc_flow_logs
    WHERE year = {year}
        AND month = {month}
        AND day = {prev_day}
        AND instance_id <> '-'
    GROUP BY action, interface_id, instance_id, flow_direction, log_status, 
             srcaddr, srcport, dstaddr, dstport, protocol
    ORDER BY total_bytes DESC
    LIMIT 50
    """.format(**query_params)

    results = {
        'traffic_comparison': traffic_comparison_df,
        'top_source_ips': execute_athena_query(source_ips_query, DATABASE_NAME),
        'top_dest_ips': execute_athena_query(dest_ips_query, DATABASE_NAME),
        'instance_traffic': execute_athena_query(instance_traffic_query, DATABASE_NAME),
        'instance_direction': execute_athena_query(instance_direction_query, DATABASE_NAME),
        'ip_pairs': execute_athena_query(ip_pairs_query, DATABASE_NAME)
    }

    # ë°”ì´íŠ¸ í˜•ì‹ ë³€í™˜ ì ìš©
    for df_name in ['top_source_ips', 'top_dest_ips', 'instance_traffic', 
                   'instance_direction', 'ip_pairs']:
        if not results[df_name].empty:
            byte_columns = [col for col in results[df_name].columns if 'bytes' in col.lower()]
            for col in byte_columns:
                results[df_name][col] = results[df_name][col].apply(format_bytes)

    return results

def calculate_data_transfer_cost(gb_amount):
    """
    AWS ë°ì´í„° ì „ì†¡ ë¹„ìš© ê³„ì‚° (ap-northeast-2 ë¦¬ì „ ê¸°ì¤€)
    - ì²˜ìŒ 10TB(=10240GB): $0.126/GB
    - ë‹¤ìŒ 40TB(=40960GB): $0.122/GB
    - ë‹¤ìŒ 100TB(=102400GB): $0.117/GB
    - 150TB ì´ˆê³¼: $0.108/GB
    (100GB ë¬´ë£Œ êµ¬ê°„ì€ ë¬´ì‹œ)
    """
    if gb_amount <= 10240:  # 10TB ì´í•˜
        return gb_amount * 0.126
    elif gb_amount <= 51200:  # 10TB-50TB
        return (10240 * 0.126) + ((gb_amount - 10240) * 0.122)
    elif gb_amount <= 153600:  # 50TB-150TB
        return (10240 * 0.126) + (40960 * 0.122) + ((gb_amount - 51200) * 0.117)
    else:  # 150TB ì´ˆê³¼
        return (10240 * 0.126) + (40960 * 0.122) + (102400 * 0.117) + ((gb_amount - 153600) * 0.108)

def format_slack_message(metrics):
    try:
        kst = pytz.timezone('Asia/Seoul')
        yesterday = (datetime.now(kst) - timedelta(days=1)).strftime('%Y-%m-%d')
        
        if metrics['traffic_comparison'].empty:
            message = [
                {
                    "type": "header",
                    "text": {
                        "type": "plain_text",
                        "text": f"ğŸ“Š AWS ë¹„ìš© ë¦¬í¬íŠ¸ ({yesterday} ê¸°ì¤€)"
                    }
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": "âš ï¸ *ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.*"
                    }
                }
            ]
            return message

        message = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": f"ğŸ“Š AWS ë¹„ìš© ë¦¬í¬íŠ¸ ({yesterday} ê¸°ì¤€)"
                }
            },
            {
                "type": "divider"
            },
            # 1. ì „ì²´ ë¹„ìš© ìš”ì•½
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ’° ì „ì²´ ë¹„ìš© ìš”ì•½*"
                }
            },
            {
                "type": "section",
                "fields": [
                    {
                        "type": "mrkdwn",
                        "text": "*ì§ì „ë‹¬ ì´ë¹„ìš©*\n_ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                    },
                    {
                        "type": "mrkdwn",
                        "text": "*ì§ì „ì¼ ì´ë¹„ìš©*\n_ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                    }
                ]
            },
            {
                "type": "divider"
            },
            # 2. ì£¼ê°„ ë¹„ìš© ë¶„ì„
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ“… ì£¼ê°„ ë¹„ìš© ë¶„ì„*"
                }
            },
            {
                "type": "section",
                "fields": [
                    {
                        "type": "mrkdwn",
                        "text": "*2ì£¼ ì „ í‰ê· *\n_ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                    },
                    {
                        "type": "mrkdwn",
                        "text": "*ì§€ë‚œì£¼ í‰ê· *\n_ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                    }
                ]
            },
            {
                "type": "divider"
            },
            # 3. Top 10 ì§€ì¶œ ì¹´í…Œê³ ë¦¬
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ† ìƒìœ„ ì§€ì¶œ ì¹´í…Œê³ ë¦¬ TOP 10*\n" +
                           "1ï¸âƒ£ EC2: _ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_\n" +
                           "2ï¸âƒ£ CloudFront: _ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_\n" +
                           "3ï¸âƒ£ DataTransfer: _ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                }
            },
            {
                "type": "divider"
            },
            # 4. ë¹„ìš© ì´ìƒ í˜„ìƒ
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*âš ï¸ ë¹„ìš© ì´ìƒ ê°ì§€*"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "_ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                }
            },
            {
                "type": "divider"
            },
            # 5. DataTransfer ìƒì„¸ ë¶„ì„
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸŒ DataTransfer ìƒì„¸ ë¶„ì„*"
                }
            }
        ]

        # í˜„ì¬ ë³´ìœ í•œ VPC Flow Logs ë°ì´í„° ì¶”ê°€
        traffic_comp = metrics['traffic_comparison'].iloc[0]
        today_gb = float(traffic_comp['today_gb'])
        today_size = f"{today_gb/1024:.2f} TB" if today_gb > 1024 else f"{today_gb:.2f} GB"
        change_pct = float(traffic_comp['change_percentage'])
        estimated_cost = calculate_data_transfer_cost(today_gb)
        unique_sources = int(traffic_comp['today_unique_sources'])
        unique_destinations = int(traffic_comp['today_unique_destinations'])
        unique_sources_str = f"{unique_sources:,}ê°œ"
        unique_destinations_str = f"{unique_destinations:,}ê°œ"

        # ë¹„ìš© ì¦ê°ë¥  ê³„ì‚°
        yesterday_gb = float(traffic_comp['yesterday_gb'])
        estimated_cost_yesterday = calculate_data_transfer_cost(yesterday_gb)
        if estimated_cost_yesterday == 0:
            cost_change_pct = 0.0
        else:
            cost_change_pct = ((estimated_cost - estimated_cost_yesterday) / estimated_cost_yesterday) * 100
        cost_change_icon = 'ğŸ“ˆ' if cost_change_pct > 0 else 'ğŸ“‰'
        cost_change_pct_str = f"{'+' if cost_change_pct > 0 else ''}{cost_change_pct:.1f}%"
        cost_change_bracket = f"({cost_change_icon} {cost_change_pct_str})"

        change_pct_icon = 'ğŸ“ˆ' if change_pct > 0 else 'ğŸ“‰'
        change_pct_str = f"{'+' if change_pct > 0 else ''}{change_pct:.1f}%"
        change_pct_bracket = f"({change_pct_icon} {change_pct_str})"

        message.extend([
            {
                "type": "section",
                "fields": [
                    {
                        "type": "mrkdwn",
                        "text": "*VPC Flow Logs ì „ì†¡ëŸ‰*\n" +
                               f"{today_size} {change_pct_bracket}\n" +
                               f"ì˜ˆìƒ ë¹„ìš©: ${estimated_cost:.2f} {cost_change_bracket}\n" +
                               f"ê³ ìœ  ì†ŒìŠ¤ IP: {unique_sources_str}\n" +
                               f"ê³ ìœ  ëŒ€ìƒ IP: {unique_destinations_str}"
                    },
                    {
                        "type": "mrkdwn",
                        "text": "*CloudFront ì „ì†¡ëŸ‰*\n_ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                    }
                ]
            },
            {
                "type": "section",
                "fields": [
                    {
                        "type": "mrkdwn",
                        "text": "*S3 ì „ì†¡ëŸ‰*\n_ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                    },
                    {
                        "type": "mrkdwn",
                        "text": "*ê¸°íƒ€ ì „ì†¡ëŸ‰*\n_ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •_"
                    }
                ]
            }
        ])

        # ê²½ê³  ë©”ì‹œì§€ (í•„ìš”í•œ ê²½ìš°)
        if change_pct > 30:
            message.append({
                "type": "context",
                "elements": [
                    {
                        "type": "mrkdwn",
                        "text": "âš ï¸ *VPC Flow Logs íŠ¸ë˜í”½ì´ ì „ì¼ ëŒ€ë¹„ 30% ì´ìƒ ì¦ê°€í–ˆìŠµë‹ˆë‹¤!*"
                    }
                ]
            })

        return message
        
    except Exception as e:
        print(f"Error formatting slack message: {str(e)}")
        return [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": f"ğŸ“Š AWS ë¹„ìš© ë¦¬í¬íŠ¸ ({yesterday} ê¸°ì¤€)"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"âš ï¸ *ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.*\n```{str(e)}```"
                }
            }
        ]

def format_detail_message(metrics):
    detail_message = []
    
    # ì†¡ì‹  íŠ¸ë˜í”½ TOP 10
    detail_message.append("ğŸ“Š *ë°ì´í„° ì „ì†¡ ìƒì„¸ ë¶„ì„*\n")
    detail_message.append("ğŸ”¹ *ì†¡ì‹  íŠ¸ë˜í”½ TOP 10 (Source IP)*")
    if not metrics['top_source_ips'].empty:
        detail_message.append(tabulate(
            metrics['top_source_ips'],
            headers=['IP', 'ì „ì†¡ëŸ‰', 'ìš”ì²­ ìˆ˜'],
            tablefmt='grid'
        ))
    
    # ìˆ˜ì‹  íŠ¸ë˜í”½ TOP 10
    detail_message.append("\nğŸ”¹ *ìˆ˜ì‹  íŠ¸ë˜í”½ TOP 10 (Destination IP)*")
    if not metrics['top_dest_ips'].empty:
        detail_message.append(tabulate(
            metrics['top_dest_ips'],
            headers=['IP', 'ìˆ˜ì‹ ëŸ‰', 'ìš”ì²­ ìˆ˜'],
            tablefmt='grid'
        ))
    
    # ì¸ìŠ¤í„´ìŠ¤ë³„ íŠ¸ë˜í”½
    detail_message.append("\nğŸ”¹ *ì¸ìŠ¤í„´ìŠ¤ë³„ íŠ¸ë˜í”½*")
    if not metrics['instance_traffic'].empty:
        detail_message.append(tabulate(
            metrics['instance_traffic'],
            headers=['Instance ID', 'Source IP', 'ì´ ì „ì†¡ëŸ‰', 'íŒ¨í‚· ìˆ˜'],
            tablefmt='grid'
        ))
    
    # ì¸ìŠ¤í„´ìŠ¤ë³„ ì¸ë°”ìš´ë“œ/ì•„ì›ƒë°”ìš´ë“œ íŠ¸ë˜í”½
    detail_message.append("\nğŸ”¹ *ì¸ìŠ¤í„´ìŠ¤ë³„ ì¸ë°”ìš´ë“œ/ì•„ì›ƒë°”ìš´ë“œ íŠ¸ë˜í”½*")
    if not metrics['instance_direction'].empty:
        detail_message.append(tabulate(
            metrics['instance_direction'],
            headers=['Instance ID', 'ë°©í–¥', 'ì „ì†¡ëŸ‰', 'ì—°ê²° ìˆ˜'],
            tablefmt='grid'
        ))
    
    # IP ìŒë³„ íŠ¸ë˜í”½ TOP 50
    detail_message.append("\nğŸ”¹ *IP ìŒë³„ íŠ¸ë˜í”½ TOP 50*")
    if not metrics['ip_pairs'].empty:
        detail_message.append(tabulate(
            metrics['ip_pairs'],
            headers=['Action', 'Interface ID', 'Instance ID', 'ë°©í–¥', 'Status', 
                    'Source IP', 'Source Port', 'Dest IP', 'Dest Port', 
                    'Protocol', 'ì „ì†¡ëŸ‰'],
            tablefmt='grid'
        ))
    
    return "\n".join(detail_message)

# =============================================================================
# CONSOLE OUTPUT FUNCTIONS (Active)
# =============================================================================

def print_console_report(message):
    """ì½˜ì†”ì— ë¦¬í¬íŠ¸ ì¶œë ¥"""
    print("\n" + "="*80)
    print("AWS ë¹„ìš© ë¦¬í¬íŠ¸")
    print("="*80)
    
    # ë©”ì‹œì§€ êµ¬ì¡°ë¥¼ ì½˜ì†” ì¶œë ¥ìœ¼ë¡œ ë³€í™˜
    for block in message:
        if block.get('type') == 'header':
            print(f"\n{block['text']['text']}")
            print("-" * len(block['text']['text']))
        elif block.get('type') == 'section':
            if 'text' in block and 'text' in block['text']:
                print(f"\n{block['text']['text']}")
            elif 'fields' in block:
                for field in block['fields']:
                    print(f"\n{field['text']}")
        elif block.get('type') == 'divider':
            print("\n" + "-" * 40)
        elif block.get('type') == 'context':
            for element in block['elements']:
                print(f"\n{element['text']}")
    
    print("\n" + "="*80)

def print_detail_report(detail_message):
    """ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ì½˜ì†”ì— ì¶œë ¥"""
    print("\n" + "="*80)
    print("ìƒì„¸ ë°ì´í„° ì „ì†¡ ë¶„ì„")
    print("="*80)
    print(detail_message)
    print("="*80)

# =============================================================================
# ARCHIVED: SLACK FUNCTIONS (Commented out for future restoration)
# =============================================================================
# To restore Slack functionality, uncomment the following functions and 
# update the main() function to use send_slack_message() instead of print_console_report()

# def send_slack_message(message):
#     response = slack.post_message(SLACK_CHANNEL_ID, None, message)
#     if response.get('ok'):
#         return response['ts']
#     else:
#         print(f"Error sending message: {response.get('error')}")
#         return None

# def send_detail_message(thread_ts, detail_message):
#     kst = pytz.timezone('Asia/Seoul')
#     now = datetime.now(kst)
    
#     response = slack.files_upload_v2(
#         channel_id=SLACK_CHANNEL_ID,
#         content=detail_message,
#         file_name=f"{now.strftime('%Y-%m-%d')}-data-transfer-details.txt",
#         title="*Data Transfer Details*",
#         thread_ts=thread_ts
#     )
    
#     if not response.get('ok'):
#         print(f"Error sending detail message: {response.get('error')}")

# =============================================================================
# MAIN EXECUTION FUNCTION (ARCHIVED - CRON DISABLED)
# =============================================================================
# This cron job has been archived and disabled.
# To re-enable: uncomment the main() function and remove the early return guard.

def main():
    # ARCHIVED: Cron job execution disabled
    print("âš ï¸  This cron job has been ARCHIVED and is not running.")
    print("ğŸ“‹ To re-enable this cron job:")
    print("   1. Uncomment the main() function below")
    print("   2. Remove this early return guard")
    print("   3. Update your cron scheduler")
    print("   4. Optionally restore Slack functionality from archived sections")
    return
    
    # ARCHIVED: Original main function (commented out)
    # print("Starting data collection...")
    # metrics = get_data_transfer_metrics()
    
    # if all(df.empty for df in metrics.values()):
    #     print("Error: All queries returned empty results")
    #     return
    
    # print("\nFormatting report...")
    # message = format_slack_message(metrics)
    
    # print("\nPrinting report to console...")
    # print_console_report(message)
    
    # print("\nPrinting detailed analysis...")
    # detail_message = format_detail_message(metrics)
    # print_detail_report(detail_message)
    
    # print("\nReport generation completed successfully!")

# =============================================================================
# ARCHIVED: SLACK VERSION OF MAIN FUNCTION
# =============================================================================
# To restore Slack functionality, replace the main() function above with this:

# def main():
#     print("Starting data collection...")
#     metrics = get_data_transfer_metrics()
    
#     if all(df.empty for df in metrics.values()):
#         print("Error: All queries returned empty results")
#         return
    
#     print("\nFormatting Slack message...")
#     message = format_slack_message(metrics)
    
#     print("\nSending to Slack...")
#     thread_ts = send_slack_message(message)
    
#     if thread_ts:
#         print("Message sent successfully")
#         detail_message = format_detail_message(metrics)
#         send_detail_message(thread_ts, detail_message)
#     else:
#         print("Failed to send message to Slack")

# =============================================================================
# CRON JOB EXECUTION (ARCHIVED)
# =============================================================================
# This cron job is currently archived and will not execute.
# The main() function has been disabled with an early return guard.

if __name__ == "__main__":
    main()